# ============================================================
# ðŸ“¡ send_data_to_firebase.py
# âœ… Sends exactly 50 readings + LSTM predictions (at 5,10,15,...)
# âœ… Adds alert counter (alert_count) when DANGER/CRITICAL occurs
# âœ… Includes safe legacy loader for older Keras models
# ============================================================

import time
import math
import random
import numpy as np
import firebase_admin
from firebase_admin import credentials, db
import joblib
import tensorflow as tf
import h5py, json

# ------------------------------------------------------------
# ðŸ”§ Firebase setup
# ------------------------------------------------------------
cred = credentials.Certificate(r"E:\Predict.Ai\ai-training\serviceAccountKey.json")
firebase_admin.initialize_app(cred, {
    'databaseURL': 'https://predict-ai-91ed3-default-rtdb.firebaseio.com/'
})

# ------------------------------------------------------------
# ðŸ©µ Safe Legacy Model Loader
# ------------------------------------------------------------
def safe_load_model(path):
    import h5py, json, tensorflow as tf

    try:
        print(f"â³ Loading model: {path}")
        return tf.keras.models.load_model(path, compile=False)
    except Exception as e:
        print(f"âš ï¸ Direct load failed: {e}")
        print("ðŸ” Attempting legacy deserialization...")

        with h5py.File(path, 'r') as f:
            model_json = f.attrs.get('model_config')
            if model_json is None:
                raise e

            # decode bytes if needed
            if isinstance(model_json, bytes):
                model_json = model_json.decode('utf-8')

            model_config = json.loads(model_json)

            # ðŸ§¹ recursive cleaner for unsupported keys
            def clean_dict(d):
                if isinstance(d, dict):
                    return {
                        k: clean_dict(v)
                        for k, v in d.items()
                        if k not in ["batch_shape", "class_name"]
                    }
                elif isinstance(d, list):
                    return [clean_dict(v) for v in d]
                else:
                    return d

            cleaned_config = clean_dict(model_config)

            # âœ… Use Keras Model reconstruction
            from tensorflow.keras.models import model_from_config
            try:
                model = model_from_config(cleaned_config)
                print(f"âœ… Legacy model successfully deserialized from {path}")
                return model
            except Exception as inner_e:
                print(f"âŒ Legacy deserialization failed: {inner_e}")
                raise inner_e


# ------------------------------------------------------------
# âš™ï¸ Load trained models & scalers safely
# ------------------------------------------------------------
pressure_model = safe_load_model("pressure_model_new.h5")
limit_model = safe_load_model("limit_switch_model_new.h5")

pressure_scaler = joblib.load("pressure_scaler.pkl")
limit_scaler = joblib.load("limit_switch_scaler.pkl")

SEQ_LEN = 20
PRED_INTERVAL = 5
TOTAL_READINGS = 50
sensor_history = {}

# ------------------------------------------------------------
# ðŸš¨ Status helper
# ------------------------------------------------------------
def get_status(value: float) -> str:
    if value < 4:
        return "DANGER"
    elif value > 10:
        return "CRITICAL"
    else:
        return "NORMAL"

# ------------------------------------------------------------
# ðŸ¤– Prediction helper
# ------------------------------------------------------------
def predict_next(sensor_id: str):
    """Predict the *next* value (i+1) after every 5 readings."""
    history = sensor_history[sensor_id]
    if len(history) < SEQ_LEN:
        return None  # wait for full sequence

    # Predict only every 5th reading
    if len(history) % PRED_INTERVAL != 0:
        return None

    arr = np.array(history[-SEQ_LEN:]).reshape(-1, 1)

    if "Pressure_Sensor" in sensor_id:
        scaled = pressure_scaler.transform(arr)
        X_input = scaled.reshape(1, SEQ_LEN, 1)
        pred_scaled = pressure_model.predict(X_input, verbose=0)[0][0]
        pred_real = pressure_scaler.inverse_transform([[pred_scaled]])[0][0]
        return float(max(0, min(15, pred_real)))

    elif "Limit_Switch" in sensor_id:
        scaled = limit_scaler.transform(arr)
        X_input = scaled.reshape(1, SEQ_LEN, 1)
        pred_scaled = limit_model.predict(X_input, verbose=0)[0][0]
        pred_real = limit_scaler.inverse_transform([[pred_scaled]])[0][0]
        return float(max(0, min(1, pred_real)))

    return None

# ------------------------------------------------------------
# ðŸ“¤ Data simulation
# ------------------------------------------------------------
def simulate_sensor_data():
    t = time.time()
    base_pressure = 7 + math.sin(t / 5) * 3 + random.uniform(-0.3, 0.3)
    data = {}

    for i in range(1, 5):
        sensor_id = f"Pressure_Sensor_0{i}_PS0{i}"
        data[sensor_id] = round(max(0, min(15, base_pressure + random.uniform(-0.5, 0.5))), 2)

    for i in range(1, 5):
        sensor_id = f"Limit_Switch_0{i}_LS0{i}"
        val = random.choice([0.0, 1.0]) + random.uniform(-0.05, 0.05)
        data[sensor_id] = round(max(0, min(1, val)), 2)

    return data

# ------------------------------------------------------------
# ðŸ”„ Send to Firebase
# ------------------------------------------------------------
def send_to_firebase(read_num):
    timestamp = time.strftime("%H:%M:%S")
    data = simulate_sensor_data()
    print(f"\nâœ… Reading {read_num}/{TOTAL_READINGS} @ {timestamp}")

    for sensor_id, value in data.items():
        if sensor_id not in sensor_history:
            sensor_history[sensor_id] = []
        sensor_history[sensor_id].append(value)
        sensor_history[sensor_id] = sensor_history[sensor_id][-SEQ_LEN:]

        predicted = predict_next(sensor_id)
        status = get_status(value)

        ref = db.reference(f"sensors/{sensor_id}")

        # ðŸ”¢ Track alert counts
        if "alert_counter" not in sensor_history:
            sensor_history["alert_counter"] = {}

        if sensor_id not in sensor_history["alert_counter"]:
            sensor_history["alert_counter"][sensor_id] = 0

        if status in ["CRITICAL", "DANGER"]:
            sensor_history["alert_counter"][sensor_id] += 1

        current_count = sensor_history["alert_counter"][sensor_id]

        ref.update({
            "actual": value,
            "predicted": predicted if predicted is not None else ref.child("predicted").get() or value,
            "status": status,
            "alert_count": current_count,
            "timestamp": timestamp
        })

        cfg_ref = db.reference(f"configuration/sensors/{sensor_id}")
        if not cfg_ref.get():
            cfg_ref.set({"active": True})

# ------------------------------------------------------------
# ðŸš€ Main loop (run exactly 50 readings)
# ------------------------------------------------------------
if __name__ == "__main__":
    print("ðŸš€ Starting 50-reading data stream...\n")
    for i in range(1, TOTAL_READINGS + 1):
        send_to_firebase(i)
        time.sleep(1.5)
    print("\nâœ… Completed 50 readings successfully! Stopping program.")
